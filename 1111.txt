Based on your conversation about Docker build memory issues, you're asking about using GitHub Actions to build Open WebUI instead of building locally. Here's a step-by-step guide:

## Step-by-Step Guide to Use GitHub Actions for Building

### Option 1: Fork and Use Existing Workflows

**Step 1: Fork the Repository**
1. Go to https://github.com/open-webui/open-webui
2. Click "Fork" to create your own copy
3. Clone your fork locally: `git clone https://github.com/YOUR_USERNAME/open-webui.git`

**Step 2: Make Your Changes**
1. Replace the logo files in `/static/favicon.png` and `/static/favicon-dark.png` with your custom logos
2. Commit and push your changes:
```bash
git add static/favicon.png static/favicon-dark.png
git commit -m "Update logo files"
git push origin main
```

**Step 3: Trigger the Build**
The main Docker build workflow [1](#5-0)  will automatically trigger when you push to the `main` branch. This workflow:

- Builds multiple image variants (standard, CUDA, Ollama) [2](#5-1) 
- Supports both `linux/amd64` and `linux/arm64` platforms
- Publishes images to GitHub Container Registry at `ghcr.io/YOUR_USERNAME/open-webui`

**Step 4: Access Your Built Images**
Once the workflow completes (usually 15-30 minutes), you can pull your custom image:
```bash
docker pull ghcr.io/YOUR_USERNAME/open-webui:main
docker run -d -p 3000:8080 ghcr.io/YOUR_USERNAME/open-webui:main
```

### Option 2: Manual Workflow Dispatch

**Step 1: Use Workflow Dispatch**
The docker-build workflow [3](#5-2)  supports manual triggering:

1. Go to your forked repository on GitHub
2. Click "Actions" tab
3. Select "Create and publish Docker images"
4. Click "Run workflow" button
5. Choose the branch and click "Run workflow"

### Option 3: Use Pre-built Images

If you don't need custom logos, you can use the official pre-built images:

```bash
# Standard image
docker pull ghcr.io/open-webui/open-webui:main

# CUDA-enabled image
docker pull ghcr.io/open-webui/open-webui:cuda

# Ollama bundled image
docker pull ghcr.io/open-webui/open-webui:ollama
```

## Build Variants Available

The GitHub Actions workflow builds several variants [4](#5-3) :

1. **Standard build**: Basic Open WebUI with `BUILD_HASH`
2. **CUDA build**: GPU acceleration with `USE_CUDA=true` [5](#5-4) 
3. **CUDA 12.6 build**: Specific CUDA version with `USE_CUDA_VER=cu126` [6](#5-5) 
4. **Ollama build**: Bundled Ollama with `USE_OLLAMA=true` [7](#5-6) 

## Frontend-Only Build

There's also a dedicated frontend build workflow [8](#5-7)  that runs `npm run build` successfully with Node.js 22, proving the memory issues you're experiencing locally don't occur in GitHub's environment.

This approach completely bypasses your local memory constraints since GitHub Actions runners have sufficient resources to handle the Pyodide and Vite build process.

Wiki pages you might want to explore:
- [Deployment and Configuration (open-webui/open-webui)](/wiki/open-webui/open-webui#15)